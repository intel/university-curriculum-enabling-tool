# =============================================
# Persona Configuration
# =============================================
PERSONA=faculty              # Default persona (faculty, lecturer, student)

# =============================================
# PM2 Process Management
# =============================================
PM2_NAMESPACE=latest           # Namespace for PM2 processes

# =============================================
# Frontend Service Configuration
# =============================================
FRONTEND_HOST=127.0.0.1        # Host to bind the web interface
FRONTEND_PORT=8080             # Port for the web interface

# =============================================
# Backend Service Configuration
# =============================================
BACKEND_HOST=127.0.0.1         # Host to bind the API service
BACKEND_PORT=8016              # Port for the API service

# =============================================
# Ollama Service Configuration
# =============================================
OLLAMA_VERSION=2.2.0           # Ollama version to install
OLLAMA_HOST=127.0.0.1:11434    # Host and port for Ollama service
OLLAMA_NUM_GPU=999             # Number of GPUs to use (999 means unlimited)
OLLAMA_KEEP_ALIVE=10m          # Keep model loaded in memory after last use
# OLLAMA_DEBUG=1               # Enable debug logging (uncomment to enable)

# Intel GPU optimization settings
ZES_ENABLE_SYSMAN=1            # Enable Intel GPU system management
SYCL_CACHE_PERSISTENT=1        # Enable persistent SYCL cache
SYCL_PI_LEVEL_ZERO_USE_IMMEDIATE_COMMANDLISTS=1  # Optimize command execution

# Default device selector - can be adjusted based on hardware
# Examples:
#   - level_zero:0 (first Intel GPU using Level Zero)
#   - opencl:0 (first GPU using OpenCL)
#   - host (use CPU)
ONEAPI_DEVICE_SELECTOR=level_zero:0

# Proxy settings
no_proxy=localhost,127.0.0.1   # Skip proxy for local connections
